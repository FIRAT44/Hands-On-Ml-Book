{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compound-productivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "[-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409    3.    ]\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "[-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409    3.    ]\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "      ocean_proximity\n",
      "17606       <1H OCEAN\n",
      "18632       <1H OCEAN\n",
      "14650      NEAR OCEAN\n",
      "3230           INLAND\n",
      "3555        <1H OCEAN\n",
      "19480          INLAND\n",
      "8879        <1H OCEAN\n",
      "13685          INLAND\n",
      "4937        <1H OCEAN\n",
      "4861        <1H OCEAN\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "[[0.]\n",
      " [0.]\n",
      " [4.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
      "      dtype=object)]\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
      "      dtype=object)]\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Predictions: [203682.37379543 326371.39370781 204218.64588245  58685.4770482\n",
      " 194213.06443039]\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "68376.64295459937\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "housing = load_housing_data()\n",
    "print(housing.head())\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "# Data Cleaning\n",
    "housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
    "housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
    "median = housing[\"total_bedrooms\"].median() # option 3\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\",axis=1) \n",
    "imputer.fit(housing_num)\n",
    "\n",
    "print(\"\\n----------------------------------\\n----------------------------------\\n\")\n",
    "print(imputer.statistics_)\n",
    "print(\"\\n----------------------------------\\n----------------------------------\\n\")\n",
    "\n",
    "print(housing_num.median().values)\n",
    "print(\"\\n----------------------------------\\n----------------------------------\\n\")\n",
    "X= imputer.transform(housing_num)\n",
    "\n",
    "housing_tr  = pd.DataFrame(X,columns=housing_num.columns)\n",
    "\n",
    "# Handling Text and Categorical Attributes\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "print(housing_cat.head(10))\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "print(housing_cat_encoded[:10])\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "print(ordinal_encoder.categories_)\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot.toarray()\n",
    "print(housing_cat_1hot.toarray())\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "print(cat_encoder.categories_)\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "\n",
    "# Customs Transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "            bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "# Transformation Pipelines\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "\n",
    "\n",
    "# Training and Evaluating on the Training Set\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "print(\"Labels:\", list(some_labels))\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "varied-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "\n",
    "print(tree_rmse)\n",
    "print(\"\\n----------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ruled-apparatus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n",
      "Scores: [69154.13209457 67178.20949022 70322.95890415 68924.04566905\n",
      " 71539.45338223 75070.21765793 68476.43341184 71769.9995391\n",
      " 76470.90054371 70796.896179  ]\n",
      "Mean: 70970.32468717915\n",
      "Standard deviation: 2767.01010268427\n",
      "None\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Scores: [66877.52325028 66608.120256   70575.91118868 74179.94799352\n",
      " 67683.32205678 71103.16843468 64782.65896552 67711.29940352\n",
      " 71080.40484136 67687.6384546 ]\n",
      "Mean: 68828.99948449331\n",
      "Standard deviation: 2662.761570610344\n",
      "None\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "print(\"Decision tree\")\n",
    "print(display_scores(tree_rmse_scores))\n",
    "\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
    "...\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "print(display_scores(lin_rmse_scores))\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "funded-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores_forets = cross_val_score(forest_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\\nforest_rmse_scores =np.sqrt(-scores)\\n\\nprint(forest_rmse)\\nprint(display_scores(forest_rmse_scores))\\nprint(\"\\n----------------------------------\\n\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "forest_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse= mean_squared_error(housing_labels,forest_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "scores_forets = cross_val_score(forest_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_rmse_scores =np.sqrt(-scores)\n",
    "\n",
    "print(forest_rmse)\n",
    "print(display_scores(forest_rmse_scores))\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "overall-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "18803.732038907292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "print(\"Random Forest\")\n",
    "print(forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daily-matter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [49604.85319566 47358.67962284 49748.99900586 52315.66315942\n",
      " 49672.07583274 53432.66401929 49054.90259011 48030.15459772\n",
      " 52952.41748561 49957.46034966]\n",
      "Mean: 50212.78698588959\n",
      "Standard deviation: 1936.1824260156664\n",
      "None\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(display_scores(forest_rmse_scores))\n",
    "print(\"\\n----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "original-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid= [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "              scoring='neg_mean_squared_error',\n",
    "              return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "iraqi-excess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hairy-habitat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=8, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=30, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "radical-premises",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65019.870548129664 {'max_features': 2, 'n_estimators': 3}\n",
      "55639.60302593755 {'max_features': 2, 'n_estimators': 10}\n",
      "53536.99354911229 {'max_features': 2, 'n_estimators': 30}\n",
      "61593.38235833468 {'max_features': 4, 'n_estimators': 3}\n",
      "53579.144360744445 {'max_features': 4, 'n_estimators': 10}\n",
      "51212.95692875872 {'max_features': 4, 'n_estimators': 30}\n",
      "60316.21816797359 {'max_features': 6, 'n_estimators': 3}\n",
      "53215.343089210706 {'max_features': 6, 'n_estimators': 10}\n",
      "50802.1482471517 {'max_features': 6, 'n_estimators': 30}\n",
      "59577.922972735236 {'max_features': 8, 'n_estimators': 3}\n",
      "52440.57185092238 {'max_features': 8, 'n_estimators': 10}\n",
      "50685.027075180806 {'max_features': 8, 'n_estimators': 30}\n",
      "63270.02698398569 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "55125.19727679271 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "60107.943993405985 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "53241.537620630974 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "59690.9793509298 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "52806.157320958344 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score),params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "armed-supplier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.10043959e-02, 5.94623289e-02, 4.46799195e-02, 1.61450458e-02,\n",
       "       1.54521599e-02, 1.61037141e-02, 1.45105590e-02, 3.83618332e-01,\n",
       "       7.37341442e-02, 3.61729284e-02, 1.08415877e-01, 4.36717687e-02,\n",
       "       6.57014981e-03, 1.14120582e-01, 1.05927593e-04, 2.54130467e-03,\n",
       "       3.69086205e-03])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mexican-outdoors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.38361833190706396, 'median_income'),\n",
       " (0.11412058228767799, 'INLAND'),\n",
       " (0.1084158772157383, 'pop_per_hhold'),\n",
       " (0.0737341441561028, 'income_cat'),\n",
       " (0.06100439587888486, 'longitude'),\n",
       " (0.05946232893190359, 'latitude'),\n",
       " (0.044679919500945554, 'housing_median_age'),\n",
       " (0.043671768741071974, 'bedrooms_per_room'),\n",
       " (0.0361729284383818, 'rooms_per_hhold'),\n",
       " (0.016145045770954807, 'total_rooms'),\n",
       " (0.01610371408252557, 'population'),\n",
       " (0.015452159923265851, 'total_bedrooms'),\n",
       " (0.01451055904098792, 'households'),\n",
       " (0.006570149814731985, '<1H OCEAN'),\n",
       " (0.0036908620477178024, 'NEAR OCEAN'),\n",
       " (0.002541304669369197, 'NEAR BAY'),\n",
       " (0.00010592759267604055, 'ISLAND')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "valuable-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reported-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46500.86049695, 50422.67152933])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    ">>> confidence = 0.95\n",
    ">>> squared_errors = (final_predictions - y_test) ** 2\n",
    ">>> np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                loc=squared_errors.mean(),\n",
    "                scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-administrator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
